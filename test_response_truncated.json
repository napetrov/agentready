{"readinessScore":50,"aiAnalysisStatus":{"enabled":true,"instructionClarity":true,"workflowAutomation":true,"contextEfficiency":true,"riskCompliance":true,"overallSuccess":true,"reason":"AI assessment analysis completed"},"categories":{"documentation":50,"instructionClarity":50,"workflowAutomation":50,"riskCompliance":50,"integrationStructure":50,"fileSizeOptimization":50},"findings":["AI assessment analysis completed"],"recommendations":["Continue improving AI readiness based on assessment results"],"detailedAnalysis":{"instructionClarity":{"stepByStepQuality":4,"commandClarity":4,"environmentSetup":3,"errorHandling":4,"dependencySpecification":3,"findings":["Instructions are clear and well-structured"],"recommendations":["Continue improving instruction clarity"],"confidence":85},"workflowAutomation":{"ciCdQuality":4,"testAutomation":4,"buildScripts":3,"deploymentAutomation":4,"monitoringLogging":3,"findings":["Workflow automation is well-implemented"],"recommendations":["Continue improving workflow automation"],"confidence":80},"contextEfficiency":{"informationCohesion":4,"terminologyConsistency":4,"crossReferenceQuality":3,"chunkingOptimization":4,"findings":["Context efficiency is good"],"recommendations":["Continue improving context efficiency"],"confidence":75},"riskCompliance":{"securityPractices":4,"complianceAlignment":4,"safetyGuidelines":3,"governanceDocumentation":4,"findings":["Risk compliance is adequate"],"recommendations":["Continue improving risk compliance"],"confidence":70},"integrationStructure":{"codeOrganization":4,"modularity":4,"apiDesign":3,"dependencies":4,"findings":["Integration structure is good"],"recommendations":["Continue improving integration structure"],"confidence":75},"fileSizeOptimization":{"criticalFileCompliance":4,"largeFileManagement":3,"contextWindowOptimization":4,"agentCompatibility":3,"findings":["File size optimization is adequate"],"recommendations":["Continue improving file size optimization"],"confidence":70}},"confidence":{"overall":75,"staticAnalysis":75,"aiAssessment":75},"staticAnalysis":{"hasReadme":true,"hasContributing":true,"hasAgents":true,"hasLicense":true,"hasWorkflows":true,"hasTests":true,"languages":["C++","Markdown","Text","Python","Shell","YAML","HTML","JSON","XML","CSS"],"errorHandling":true,"fileCount":5429,"linesOfCode":554100,"repositorySizeMB":97.36,"readmeContent":"# oneAPI Data Analytics Library MySQL\\* Samples\n\nMySQL\\* samples for the oneAPI Data Analytics Library (oneDAL) are designed to show how to use this library with a MySQL database in a C++ application.\n\nUnzip the archive with oneDAL samples to your working directory (`<sample_dir>`).\n\n## System Requirements\nYou can use oneDAL MySQL\\* samples on Linux\\*, Windows\\*, and macOS\\* operating systems. For a list of oneDAL hardware and software requirements, refer to release notes for the version of oneDAL you are using.\n\n### MySQL\\* implementations against which oneDAL has been validated:\n- MySQL 5.6.22\n\n**Note:** oneDAL is expected to work on other MySQL version as well. Let us know if you have any troubles with the distribution you are using.\n\n## Preparation Before Build and Run\n### MySQL support\nYou can download and install the MySQL\\* application from [the official web page][mysql]. To be able to use MySQL\\* C++  samples, make sure to configure the ODBC connector for the user who has permissions to create tables in the database. Also, make sure to replace the `mySQL_test` and `mySQL_test_32` database names in the `datasource_mysql.cpp` sample file with the actual database name you plan to use:\n\nIf your ODBC connector on Windows\\* is installed in a directory different from `C:\\Program Files (x86)\\Windows Kits\\8.1\\Lib\\winv6.3\\um\\`, make sure to update the `ODBC_PATH` variable in the `launcher.bat` script with the correct path before running the script.\n\n### Setting Up the Build Environment\nBefore you build the sample, you must set certain environment variables that define the location of related libraries. The oneDAL includes the `vars` scripts that you can run to set environment variables:\n\n- On Windows\\*, you can find the `vars.bat` batch file at `<install-dir>\\compilers_and_libraries_xxxx.x.xxx\\windows\\daal\\bin\\:\nvars.bat`\n- On Linux\\*, you can find the `vars.sh` shell script at `<install-dir>\\compilers_and_libraries_xxxx.x.xxx\\linux\\daal\\bin:\nsource vars.sh`\n- On macOS\\*, you can find the `vars.sh` shell script at `<install-dir>\\compilers_and_libraries_xxxx.x.xxx\\mac\\daal\\bin:\nsource vars.sh`\n\nFor more information about setting environment variables and configuring oneDAL, refer to Getting Started guides for the library.\n\n## Build and Run Instructions\n### On Windows\\*\nTo build oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `launcher` command with the `build` parameter:\n\n```\ncd <sample_dir>\\cpp\\mysql\n\nlauncher.bat build\n```\n\nThe command creates the `.\\_results\\intel64` directory and builds `*.exe` executables and `*.exe` libraries, as well as creates a log file for build results.\n\nTo run oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `launcher` command with the `run` parameter:\n\n```\ncd <sample_dir>\\cpp\\mysql\n\nlauncher.bat run\n```\n\nSelect the same architecture parameter as you provided to the `launcher` command with the `build` parameter.\n\nFor each sample, the results are placed into the `.\\_results\\intel64\\<sample name>\\.res` file, depending on the specified architecture.\n\n### On Linux\\*\nTo build oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `make` command:\n\n```\ncd <sample_dir>/cpp/mysql\n\nmake {libintel64|sointel64} compiler={intel|gnu} mode=build\n```\n\nFrom the `{libintel64|sointel64}` parameters, select the one that matches the architecture parameter you provided to the `vars.sh` script and that has the prefix that matches the type of executables you want to build: `lib` for static and `so` for dynamic executables.\n\nThe command creates a directory for the chosen compiler, architecture, and library extension (`a` or `so`). For example: `_results/intel_intel64_a`.\n\nTo run oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `make` command in the run mode. For example, if you run the `vars` script with the `intel64` target:\n\n```\ncd <sample_dir>/cpp/mysql\n\nmake libintel64 mode=run\n```\n\nThe `make` command builds a static library for the Intel(R) 64 architecture and runs the executable.\n\n### On macOS\\*\nTo build oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `make` command:\n\n```\ncd <sample_dir>/cpp/mysql\n\nmake {libintel64|dylibintel64} compiler={intel|gnu|clang} mode=build\n```\n\nFrom the `{libintel64|dylibintel64}` parameters, select the one that matches the architecture parameter you provided to the `vars.sh` script and that has the prefix that matches the type of executables you want to build: `lib` for static and `dylib` for dynamic executables.\n\nThe command creates a directory for the chosen compiler, architecture, and library extension (`a` or `dylib`). For example: `_results/intel_intel64_a`.\n\nTo run oneDAL MySQL C++ samples, go to the C++ MySQL samples directory and execute the `make` command in the run mode. For example, if you run the `vars` script with the `intel64` target:\n\n```\ncd <sample_dir>/cpp/mysql\n\nmake libintel64 mode=run\n```\n\nThe `make` comm... [truncated]","contributingContent":"<!--\n******************************************************************************\n* Copyright 2014 Intel Corporation\n*\n* Licensed under the Apache License, Version 2.0 (the \"License\");\n* you may not use this file except in compliance with the License.\n* You may obtain a copy of the License at\n*\n*     http://www.apache.org/licenses/LICENSE-2.0\n*\n* Unless required by applicable law or agreed to in writing, software\n* distributed under the License is distributed on an \"AS IS\" BASIS,\n* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n* See the License for the specific language governing permissions and\n* limitations under the License.\n*******************************************************************************/-->\n\n# How to Contribute\nWe welcome community contributions to oneAPI Data Analytics Library. You can:\n\n- Submit your changes directly with a [pull request](https://github.com/uxlfoundation/oneDAL/pulls).\n- Log a bug or make a feature request with an [issue](https://github.com/uxlfoundation/oneDAL/issues).\n\nRefer to our guidelines on [pull requests](#pull-requests) and [issues](#issues) before you proceed.\n\n## Contacting maintainers\nYou may reach out to Intel project maintainers privately at onedal.maintainers@intel.com.\n[Codeowners](https://github.com/uxlfoundation/oneDAL/blob/main/.github/CODEOWNERS) configuration defines specific maintainers for corresponding code sections, however it's currently limited to Intel members. With further migration to UXL we will be changing this, but here are non-Intel contacts:\n\nFor ARM specifics you may contact: [@rakshithgb-fujitsu](https://github.com/rakshithgb-fujitsu/)\n\nFor RISC-V specifics you may contact: [@keeranroth](https://github.com/keeranroth/)\n\n## Issues\n\nUse [GitHub issues](https://github.com/uxlfoundation/oneDAL/issues) to:\n- report an issue\n- make a feature request\n\n**Note**: To report a vulnerability, refer to [Intel vulnerability reporting policy](https://www.intel.com/content/www/us/en/security-center/default.html).\n\n## Pull Requests\n\nTo contribute your changes directly to the repository, do the following:\n- Make sure you can build the product and run all the examples with your patch.\n- Product uses bazel for validation and your changes should pass tests. Please add new tests as necessary. [Bazel Guide for oneDAL](https://github.com/uxlfoundation/oneDAL/tree/main/dev/bazel)\n- Make sure your code is in line with our [coding style](#code-style) as `clang-format` is one of the checks in our public CI.\n- For a larger feature, provide a relevant example, and tests.\n- [Document](#documentation-guidelines) your code.\n- [Submit](https://github.com/uxlfoundation/oneDAL/pulls) a pull request into the `main` branch.\n\nPublic and private CIs are enabled for the repository. Your PR should pass all of our checks. We will review your contribution and, if any additional fixes or modifications are necessary, we may give some feedback to guide you. When accepted, your pull request will be merged into our GitHub* repository.\n\n## Code Style\n\n### ClangFormat\n\n**Prerequisites:** ClangFormat `9.0.0` or later\n\nOur repository contains [clang-format configurations](https://github.com/uxlfoundation/oneDAL/blob/main/.clang-format) that you should use on your code. To do this, run:\n\n```\nclang-format style=file <your file>\n```\n\nRefer to [ClangFormat documentation](https://clang.llvm.org/docs/ClangFormat.html) for more information.\n\n### editorconfig-checker\n\nWe also recommend using [editorconfig-checker](https://github.com/editorconfig-checker/editorconfig-checker) to ensure your code adheres to the project's coding style. EditorConfig-Checker is a command-line tool that checks your code against the rules defined in the [.editorconfig](https://github.com/uxlfoundation/oneDAL/blob/main/.editorconfig) file.\n\nTo use it, follow these steps:\n\n1. Install the tool by following the instructions in the [official documentation](https://github.com/editorconfig-checker/editorconfig-checker#installation).\n2. Navigate to the root directory of your project.\n3. Run the following command to check your code:\n\n```\neditorconfig-checker\n```\n\n### Coding Guidelines\n\nFor your convenience we also added [coding guidelines](https://uxlfoundation.github.io/oneDAL/contribution/coding_guide.html) with examples and detailed descriptions of the coding style oneDAL follows. We encourage you to consult them when writing your code.\n\n## Custom Components\n\n### CPU Features Dispatching\n\noneDAL provides binaries that can contain code targeting different architectural extensions of a base instruction set architecture (ISA). For example, code paths can exist for AVX2, AVX-512 extensions, on top of the x86-64 base architecture. oneDAL chooses the code path which is most suitable for that implementation.\nContributors should leverage [CPU Features Dispatching](http://uxlfoundation.github.io/oneDAL/contribution/cpu_features.html) mechanism to implement the code of the algorithms that can perform mo... [truncated]","agentsContent":"\n# Examples - AI Agents Context\n\n> **Purpose**: Context for AI agents working with oneDAL example patterns demonstrating dual C++ interface usage.\n\n## 🏗️ Examples Architecture\n\noneDAL examples demonstrate **three distinct interface patterns** corresponding to the dual C++ architecture:\n\n### Interface Categories\n- **DAAL Interface** (`examples/daal/cpp/source/`) - Traditional CPU-focused patterns\n- **oneAPI CPU** (`examples/oneapi/cpp/source/`) - Modern C++ with fluent interfaces  \n- **oneAPI GPU** (`examples/oneapi/dpc/source/`) - Heterogeneous computing with SYCL\n\n## 📁 Structure\n```\nexamples/\n├── daal/cpp/source/           # Traditional DAAL interface examples\n│   ├── covariance/           # Algorithm-specific examples\n│   ├── kmeans/               # K-means clustering examples\n│   └── [algorithms]/         # Other algorithm examples\n├── oneapi/cpp/source/         # Modern oneAPI CPU examples\n│   ├── covariance/           # Same algorithms, modern interface\n│   ├── kmeans/               # Modern K-means patterns\n│   └── example_util/         # Shared utilities\n└── oneapi/dpc/source/         # GPU-accelerated examples\n    ├── kmeans/               # SYCL-enabled K-means\n    └── [algorithms]/         # GPU algorithm examples\n```\n\n## 🎭 Interface Pattern Comparison\n\n### 1. DAAL Traditional Pattern\n```cpp\n// Explicit lifecycle management with status codes\n#include \"daal.h\"\nusing namespace daal::algorithms;\n\ncovariance::Batch<> algorithm;\nalgorithm.input.set(covariance::data, dataSource.getNumericTable());\nalgorithm.compute();\ncovariance::ResultPtr res = algorithm.getResult();\nprintNumericTable(res->get(covariance::covariance), \"Covariance matrix:\");\n```\n\n**Characteristics:**\n- **Headers**: `#include \"daal.h\"` with `using namespace daal::algorithms`\n- **Memory**: Custom `SharedPtr<T>` and `NumericTable` management\n- **Workflow**: Instantiate → set input → compute() → getResult()\n- **Error Handling**: Implicit status checking\n\n### 2. oneAPI CPU Pattern\n```cpp\n// Modern fluent interface with RAII\n#include \"oneapi/dal/algo/kmeans.hpp\"\nnamespace dal = oneapi::dal;\n\nconst auto kmeans_desc = dal::kmeans::descriptor<>()\n                             .set_cluster_count(20)\n                             .set_max_iteration_count(5)\n                             .set_accuracy_threshold(0.001);\nconst auto result_train = dal::train(kmeans_desc, x_train, initial_centroids);\nstd::cout << \"Centroids:\\n\" << result_train.get_model().get_centroids() << std::endl;\n```\n\n**Characteristics:**\n- **Headers**: `#include \"oneapi/dal/algo/[algorithm].hpp\"`\n- **Memory**: STL RAII with automatic resource management\n- **Workflow**: Descriptor configuration → train/compute → result access\n- **Data**: Modern `dal::table` with CSV data sources\n\n### 3. oneAPI GPU Pattern\n```cpp\n// SYCL queue integration for heterogeneous computing\n#include <sycl/sycl.hpp>\n#include \"oneapi/dal/algo/kmeans.hpp\"\n\nvoid run(sycl::queue &q) {\n    const auto x_train = dal::read<dal::table>(q, dal::csv::data_source{...});\n    const auto result_train = dal::train(q, kmeans_desc, x_train, initial_centroids);\n}\n```\n\n**Characteristics:**\n- **Headers**: SYCL integration with `#include <sycl/sycl.hpp>`\n- **Queue Parameter**: All operations accept `sycl::queue& q` as first parameter\n- **Data Loading**: Queue-aware `dal::read<dal::table>(q, data_source)`\n- **Execution**: GPU-accelerated with same API as CPU version\n\n## 🔧 Build System Integration\n\n### Bazel Configuration\n```python\n# examples/oneapi/cpp/BUILD\ndal_example_suite(\n    name = \"kmeans\",\n    compile_as = [\"c++\"],\n    srcs = glob([\"source/kmeans/*.cpp\"]),\n    dal_deps = [\"@onedal//cpp/oneapi/dal/algo:kmeans\"],\n    data = [\"@onedal//examples/oneapi:data\"],\n    extra_deps = [\":example_util\", \"@opencl//:opencl_binary\"],\n)\n```\n\n### Common Patterns\n- **Algorithm Suites**: Each algorithm gets `dal_example_suite` target\n- **Shared Utilities**: `example_util` module for common helpers\n- **Data Dependencies**: Centralized test data management\n- **OpenCL Integration**: GPU examples require OpenCL binary dependencies\n\n## 🎯 Example Usage Patterns\n\n### Data Loading Evolution\n```cpp\n// DAAL: Explicit data source management\nFileDataSource<CSVFeatureManager> dataSource(fileName, \n                                             DataSource::doAllocateNumericTable,\n                                             DataSource::doDictionaryFromContext);\ndataSource.loadDataBlock();\n\n// oneAPI CPU: Modern data loading\nconst auto input = dal::read<dal::table>(dal::csv::data_source{fileName});\n\n// oneAPI GPU: Queue-aware data loading  \nconst auto input = dal::read<dal::table>(queue, dal::csv::data_source{fileName});\n```\n\n### Algorithm Configuration Evolution\n```cpp\n// DAAL: Parameter-based configuration\nconst size_t nClusters = 20;\nconst size_t nIterations = 5;\n// Configuration through algorithm parameters\n\n// oneAPI: Fluent descriptor pattern\nconst auto desc = dal::kmeans::descriptor<>()\n                      .set_cluster_count(20)\n                  ... [truncated]","workflowFiles":["oneDAL-main/.github/workflows/ci-aarch64.yml","oneDAL-main/.github/workflows/ci.yml","oneDAL-main/.github/workflows/docker-validation-ci.yml","oneDAL-main/.github/workflows/docker-validation-nightly.yml","oneDAL-main/.github/workflows/docs-release.yml","oneDAL-main/.github/workflows/label-enforcement.yml","oneDAL-main/.github/workflows/nightly-build.yml","oneDAL-main/.github/workflows/nightly-test.yml","oneDAL-main/.github/workflows/openssf-scorecard.yml","oneDAL-main/.github/workflows/pr-checklist.yml","oneDAL-main/.github/workflows/renovate-validation.yml","oneDAL-main/.github/workflows/skywalking-eyes.yml","oneDAL-main/.github/workflows/slack-pr-notification.yml"],"testFiles":["oneDAL-main/.ci/scripts/test.bat","oneDAL-main/.ci/scripts/test.sh","oneDAL-main/.github/workflows/nightly-test.yml","oneDAL-main/cpp/daal/src/algorithms/dtrees/gbt/regression/test/","oneDAL-main/cpp/daal/src/algorithms/dtrees/gbt/regression/test/gbt_regression_model_builder_unit.cpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/badargs.cpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/online.cpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/online_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/basic_statistics/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/connected_components/test/","oneDAL-main/cpp/oneapi/dal/algo/connected_components/test/connected_components_test.cpp","oneDAL-main/cpp/oneapi/dal/algo/correlation_distance/test/","oneDAL-main/cpp/oneapi/dal/algo/correlation_distance/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/cosine_distance/test/","oneDAL-main/cpp/oneapi/dal/algo/cosine_distance/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/badargs.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/compute_parameters.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/online.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/online_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/covariance/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/ccl_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/data.hpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/mpi_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/spmd_backend_fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/dbscan/test/spmd_backend_template.hpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/infer_parameters.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/overflow.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/serialization.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_forest/test/train_parameters.cpp","oneDAL-main/cpp/oneapi/dal/algo/decision_tree/backend/test/","oneDAL-main/cpp/oneapi/dal/algo/decision_tree/backend/test/node_info.cpp","oneDAL-main/cpp/oneapi/dal/algo/finiteness_checker/test/","oneDAL-main/cpp/oneapi/dal/algo/finiteness_checker/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/jaccard/test/","oneDAL-main/cpp/oneapi/dal/algo/jaccard/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/jaccard/test/jaccard_test.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/backend/gpu/test/","oneDAL-main/cpp/oneapi/dal/algo/kmeans/backend/gpu/test/cluster_updater_dpc.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/backend/gpu/test/empty_cluster_handling_dpc.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/backend/gpu/test/perf_batch_impl_dpc.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/ccl_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/data.hpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/mpi_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/serialization.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/spmd_backend_fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans/test/spmd_backend_template.hpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans_init/test/","oneDAL-main/cpp/oneapi/dal/algo/kmeans_init/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans_init/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans_init/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/kmeans_init/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/knn/test/","oneDAL-main/cpp/oneapi/dal/algo/knn/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/knn/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/knn/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/knn/test/serialization.cpp","oneDAL-main/cpp/oneapi/dal/algo/knn/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_kernel/test/","oneDAL-main/cpp/oneapi/dal/algo/linear_kernel/test/badargs.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_kernel/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_kernel/test/overflow.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/batch.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/online.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/online_spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/serialization.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/spmd.cpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/spmd_backend_template.hpp","oneDAL-main/cpp/oneapi/dal/algo/linear_regression/test/train_parameters.cpp","oneDAL-main/cpp/oneapi/dal/algo/logistic_regression/test/","oneDAL-main/cpp/oneapi/dal/algo/logistic_regression/test/batch_dpc.cpp","oneDAL-main/cpp/oneapi/dal/algo/logistic_regression/test/fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/logistic_regression/test/spmd_dpc.cpp","oneDAL-main/cpp/oneapi/dal/algo/logistic_regression/test/spmd_fixture.hpp","oneDAL-main/cpp/oneapi/dal/algo/louvain/test/","oneDAL-main/cpp/oneapi/dal/algo/louvain/test/badarg.cpp","oneDAL-main/cpp/oneapi/dal/algo/louvain/test/louvain_test.cpp","oneDAL-main/cpp/oneapi/dal/algo/objective_function/test/"],"fileSizeAnalysis":{"totalSizeMB":8.4,"largeFiles":[],"criticalFiles":[{"path":"oneDAL-main/README.md","sizeMB":0.008514404296875,"agentLimit":100,"status":"warning"},{"path":"oneDAL-main/.ci/AGENTS.md","sizeMB":0.004530906677246094,"agentLimit":100,"status":"warning"},{"path":"oneDAL-main/AGENTS.md","sizeMB":0.004303932189941406,"agentLimit":100,"status":"warning"},{"path":"oneDAL-main/cpp/AGENTS.md","sizeMB":0.006117820739746094,"agentLimit":100,"status":"warning"},{"path":"oneDAL-main/cpp/daal/AGENTS.md","sizeMB":0.004620552062988281,"agentLimit":100,"status":"warning"},{"path":"oneDAL-main/CONTRIBUTING.md","sizeMB":0.006732940673828125,"agentLimit":100,"status":"warning"}],"agentCompatibility":{"cursor":{"score":100,"status":"compliant","issues":[]},"githubCopilot":{"score":100,"status":"compliant","issues":[]},"claudeWeb":{"score":100,"status":"compliant","issues":[]},"claudeAPI":{"score":100,"status":"compliant","issues":[]},"chatgpt":{"score":75,"status":"warning","issues":["ChatGPT compatibility: 75% (placeholder)"]},"overall":{"score":100,"status":"compliant","issues":[]}},"recommendations":["Repository files are well-optimized for AI agent consumption","Consider maintaining current file size practices for optimal AI agent performance","Regularly review file sizes as the repository grows to maintain AI agent compatibility"]}}}